{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRNMsAU8YIrM"
      },
      "source": [
        "Upload video - https://drive.google.com/file/d/12GVWPM8YZr5Xj9U_Zdt6oBfHO-Dtz2ow/ - to your google drive account (or just to this colab instance if you don't want persistance)\n",
        "\n",
        "Takes 6-10 hours to train, wave mouse around in window occasionally so you don't get timed out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BNNdfifXO-L",
        "outputId": "f4fe4cc8-cf37-4dcd-bc40-f0cb0ef27df5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6ywIWzhZKVI"
      },
      "source": [
        "Enter video path below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnzE81IzZNGJ"
      },
      "source": [
        "video_path = \"gdrive/MyDrive/p_sim_long_3_slow.npy\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NKTnMbHZNft"
      },
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class Simulation(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def reset():\n",
        "        '''\n",
        "        Reset simulation state\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def sim_step():\n",
        "        '''\n",
        "        Run one step of the simulation\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def draw():\n",
        "        '''\n",
        "        Render the state of the simulation\n",
        "        '''\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beIGh_tHAIn7"
      },
      "source": [
        "#import Simulation, Particle, Walls\n",
        "\n",
        "class VideoSimulation(Simulation):\n",
        "    '''\n",
        "    Batched Pre-rendered simulation\n",
        "    Takes a numpy like array representing a video\n",
        "    of a grid simulation and steps through them\n",
        "    '''\n",
        "\n",
        "    def __init__(self, data_arr, batch_size, model_steps_per_frame):\n",
        "        self.sim_data = data_arr\n",
        "        print(f'Initialized VideoSimulation with data: {data_arr.shape}')\n",
        "        self.t_steps = data_arr.shape[0]\n",
        "        self.grid_height = data_arr.shape[1]\n",
        "        self.grid_width = data_arr.shape[2]\n",
        "        self.batch_size = batch_size\n",
        "        self.model_steps_per_frame = model_steps_per_frame\n",
        "        self.initial_indices = np.arange(0,batch_size)*(self.t_steps-(self.t_steps%batch_size))//batch_size\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_indices = np.copy(self.initial_indices)\n",
        "        self.sim_steps = 0\n",
        "\n",
        "    def sim_step(self, time_step):\n",
        "        if self.sim_steps % self.model_steps_per_frame == 0:\n",
        "            self.cur_indices += 1\n",
        "            self.cur_indices = np.mod(self.cur_indices, self.t_steps)\n",
        "        self.sim_steps += 1\n",
        "\n",
        "    def draw(self):\n",
        "        return self.sim_data[self.cur_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq3oxT-qA_jd"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import base64\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "class CAModel(nn.Module):\n",
        "\n",
        "    def __init__(self, env_d, hidden_d, device):\n",
        "        super(CAModel, self).__init__()\n",
        "        self.env_d = env_d\n",
        "        self.conv1 = nn.Conv2d(env_d*3, hidden_d, 1).to(device)\n",
        "        self.conv2 = nn.Conv2d(hidden_d, env_d, 1).to(device)\n",
        "        nn.init.zeros_(self.conv2.weight)\n",
        "        nn.init.zeros_(self.conv2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return self.conv2(x)\n",
        "\n",
        "    def pack_layer(self, weight, bias, outputType):\n",
        "      in_ch, out_ch = weight.shape\n",
        "      assert (in_ch%4==0)\n",
        "      assert (out_ch%4==0)\n",
        "      print(f'in_ch: {in_ch} out_ch: {out_ch}')\n",
        "      print(f'bias.shape {bias.shape}')\n",
        "      assert (bias.shape==(out_ch,))\n",
        "      weight_scale, bias_scale = 1.0, 1.0\n",
        "      if outputType == np.uint8:\n",
        "        weight_scale = 2.0*np.abs(weight).max()\n",
        "        bias_scale = 2.0*np.abs(bias).max()\n",
        "        weight = np.round((weight/weight_scale+0.5)*255)\n",
        "        bias = np.round((bias/bias_scale+0.5)*255)\n",
        "      packed = np.vstack([weight, bias[None,...]])\n",
        "      packed = packed.reshape(in_ch+1, out_ch//4, 4)\n",
        "      packed = outputType(packed)\n",
        "      packed_b64 = base64.b64encode(packed.tobytes()).decode('ascii')\n",
        "      return {'data_b64': packed_b64, 'in_ch': in_ch, 'out_ch': out_ch,\n",
        "              'weight_scale': weight_scale, 'bias_scale': bias_scale,\n",
        "              'type': outputType.__name__}\n",
        "\n",
        "    def export_pytorch_ca_to_webgl_demo(self, outputType=np.uint8):\n",
        "      # reorder the first layer inputs to meet webgl demo perception layout\n",
        "      w1 = self.conv1.weight.squeeze().cpu().detach().permute(1,0).numpy()\n",
        "      w1 = w1.reshape(self.env_d, 3, -1).transpose(1, 0, 2).reshape(3*self.env_d, -1)\n",
        "      print(f'w1 shape: {w1.shape}')\n",
        "      w2 = self.conv2.weight.squeeze().cpu().detach().permute(1,0).numpy()\n",
        "\n",
        "      layers = [\n",
        "          self.pack_layer(w1, self.conv1.bias.cpu().detach().numpy(), outputType),\n",
        "          self.pack_layer(w2, self.conv2.bias.cpu().detach().numpy(), outputType)\n",
        "      ]\n",
        "      return json.dumps(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56v7M9JmBSoO"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#import Simulation\n",
        "\n",
        "class CASimulation(Simulation):\n",
        "\n",
        "    def __init__(self, ca_model, device, batch_size, env_size=32, env_depth=16, update_prob=0.5):\n",
        "        self.model = ca_model\n",
        "        self.env_size = env_size\n",
        "        self.env_depth = env_depth\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.update_probability = update_prob\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = torch.zeros(\n",
        "            self.batch_size, self.env_depth, self.env_size, self.env_size,\n",
        "            device=self.device)\n",
        "\n",
        "    def wrap_edges(self, x):\n",
        "        return F.pad(x, (1,1,1,1), 'circular', 0)\n",
        "\n",
        "    def raw_senses(self):\n",
        "        # states - (batch, depth, x, y)\n",
        "        sobel_x = torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]], device=self.device)/8\n",
        "        sobel_y = torch.tensor([[1.0,2.0,1.0],[0.0,0.0,0.0],[-1.0,-2.0,-1.0]], device=self.device)/8\n",
        "        identity = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]], device=self.device)\n",
        "        all_filters = torch.stack((identity, sobel_x, sobel_y))\n",
        "        all_filters_batch = all_filters.repeat(self.env_depth,1,1).unsqueeze(1)\n",
        "        return F.conv2d(\n",
        "            self.wrap_edges(self.states),\n",
        "            all_filters_batch,\n",
        "            groups=self.env_depth\n",
        "        )\n",
        "\n",
        "    def sim_step(self, time_step):\n",
        "        states_updates = self.model(self.raw_senses())*time_step\n",
        "        # randomly block updates to enforce\n",
        "        # asynchronous communication between cells\n",
        "        rand_mask = torch.rand_like(\n",
        "            self.states[:, :1, :, :], device=self.device) < self.update_probability\n",
        "        self.states += states_updates*(rand_mask.float())\n",
        "\n",
        "    def draw(self):\n",
        "        return self.states[:,0:3,:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQQyJI1GCNRs"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import random\n",
        "import math\n",
        "\n",
        "class CATrainer:\n",
        "\n",
        "    def __init__(self, learned_model, ground_truth_model,\n",
        "                 sim_step_blocks_per_run=4, seed=115, lr=2e-3, lr_decay=1024*1024,\n",
        "                 checkpoint_interval=1, checkpoint_path='checkpoints',\n",
        "                 sim_steps_per_draw=8, gt_reset_interval=512, time_step=1.0,\n",
        "                 save_final_state_interval=4, save_evolution_interval=256):\n",
        "        self.gt_model = ground_truth_model\n",
        "        self.ml_model = learned_model\n",
        "        self.gt_reset_interval = gt_reset_interval\n",
        "        self.sim_step_blocks_per_run = sim_step_blocks_per_run\n",
        "        self.sim_steps_per_draw = sim_steps_per_draw\n",
        "        self.time_step = time_step\n",
        "        self.checkpoint_interval = checkpoint_interval\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.save_final_state_interval = save_final_state_interval\n",
        "        self.save_evolution_interval = save_evolution_interval\n",
        "        self.run_name = \"output/{:%Y_%m_%d_%H_%M_%S}\".format(datetime.now())\n",
        "        self.lr = lr\n",
        "        self.lr_decay = lr_decay\n",
        "        random.seed(seed)\n",
        "\n",
        "    def train_standard(self, optim_steps):\n",
        "        final_state_count = 0\n",
        "        evolution_count = 0\n",
        "        running_loss = 0\n",
        "        optimizer = optim.Adam(self.ml_model.model.parameters(), lr=self.lr)\n",
        "        r_losses = np.zeros(self.sim_step_blocks_per_run)\n",
        "        running_loss = 0\n",
        "        for o_i in tqdm(range(1, optim_steps)):\n",
        "\n",
        "            if o_i%self.gt_reset_interval == 0:\n",
        "                self.gt_model.reset()\n",
        "\n",
        "            new_lrate = self.lr * (0.25 ** (o_i / self.lr_decay))\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = new_lrate\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # set initial state from ground truth model\n",
        "            self.ml_model.reset()\n",
        "            self.ml_model.states[:, 0:3, :, :] = self.gt_model.draw()\n",
        "\n",
        "            c_loss = 0\n",
        "            c_losses = []\n",
        "\n",
        "            for s_i in range(self.sim_step_blocks_per_run):\n",
        "\n",
        "                for sub_i in range(self.sim_steps_per_draw):\n",
        "                    self.gt_model.sim_step(self.time_step)\n",
        "                    self.ml_model.sim_step(self.time_step)\n",
        "                    if o_i%self.save_evolution_interval == 0:\n",
        "                        self.save_img(self.ml_model.draw()[0],\n",
        "                                      'evolution_output', 'evo', evolution_count)\n",
        "                        self.save_img(self.gt_model.draw()[0],\n",
        "                                      'evolution_output_gt', 'evo', evolution_count)\n",
        "                        evolution_count += 1\n",
        "\n",
        "                gt_state = self.gt_model.draw()\n",
        "                ml_state = self.ml_model.draw()\n",
        "\n",
        "                loss = F.mse_loss(ml_state, gt_state)\n",
        "                loss.backward(retain_graph=True)\n",
        "                c_loss += loss.item()\n",
        "                c_losses.append(loss.item())\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if o_i%self.save_final_state_interval == 0:\n",
        "                self.save_img(ml_state[0], 'final_state_output', 'final_state', final_state_count)\n",
        "                final_state_count += 1\n",
        "\n",
        "\n",
        "            if o_i == 0:\n",
        "                r_losses += np.array(c_losses)\n",
        "                running_loss = c_loss\n",
        "            else:\n",
        "                running_loss = 0.99*running_loss + 0.01*c_loss\n",
        "                r_losses = 0.99*r_losses + 0.01*np.array(c_losses)\n",
        "            assert math.isclose(r_losses.sum(), running_loss)\n",
        "            if (o_i % 50 == 0):\n",
        "                tqdm.write(f'run {o_i}, recent loss: {running_loss:.7f}, lr: {new_lrate:.5f} \\nblock losses: {r_losses}')\n",
        "            if o_i%self.checkpoint_interval == 0:\n",
        "                self.save_model(f'ca_model_step_{o_i:06d}')\n",
        "\n",
        "    def save_img(self, t, pth, fname, i):\n",
        "        pth = self.run_name + '/' + pth\n",
        "        Path(pth).mkdir(exist_ok=True, parents=True)\n",
        "        normed = (torch.clamp(t.detach(),0.0,1.0)*255)\n",
        "        im = Image.fromarray(normed.permute(1,2,0).cpu().numpy().astype(np.uint8))\n",
        "        im.save(f'{pth}/{fname}_step_{i:06d}.png')\n",
        "\n",
        "    def save_model(self, fname):\n",
        "        pth = self.run_name + '/' + self.checkpoint_path\n",
        "        Path(pth).mkdir(exist_ok=True, parents=True)\n",
        "        torch.save(self.ml_model.model, f'{pth}/{fname}.pt')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "WkapSi2k_7Pg",
        "outputId": "3e00cdb1-e7ba-4ac5-e8fb-40a87ef24afb"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "#import VideoSimulation, CAModel, CASimulation, CATrainer\n",
        "\n",
        "\n",
        "cell_dim = 16\n",
        "hidden_dim = 160\n",
        "batch_size = 24\n",
        "train_steps = 4096*4\n",
        "learning_rate = 2e-3\n",
        "lr_decay_rate = 1024*24\n",
        "model_steps_per_video_frame = 8\n",
        "step_blocks = 16\n",
        "seed = 55\n",
        "video_data_path = video_path # paste in appropriate path\n",
        "device = torch.device('cuda')\n",
        "pretrain_path = None\n",
        "if pretrain_path == None:\n",
        "    ca_model = CAModel(cell_dim, hidden_dim, device)\n",
        "else:\n",
        "    ca_model = torch.load(pretrain_path)\n",
        "\n",
        "video_data = torch.tensor(\n",
        "    np.load(video_data_path).astype(np.float32)/255,\n",
        "    device=device).permute(0, 3, 1, 2)\n",
        "\n",
        "video_sim = VideoSimulation(\n",
        "    video_data,\n",
        "    batch_size,\n",
        "    model_steps_per_video_frame\n",
        ")\n",
        "\n",
        "ca_sim = CASimulation(\n",
        "    ca_model, device, batch_size,\n",
        "    env_size=video_data.shape[2], env_depth=cell_dim\n",
        ")\n",
        "\n",
        "trainer = CATrainer(\n",
        "    ca_sim, video_sim, sim_step_blocks_per_run=step_blocks,\n",
        "    save_evolution_interval=1024, lr=learning_rate, lr_decay=lr_decay_rate,\n",
        "    save_final_state_interval=16, sim_steps_per_draw=model_steps_per_video_frame,\n",
        "    seed=seed, gt_reset_interval=10000000, checkpoint_path=f'checkpoints_c{cell_dim}_h{hidden_dim}'\n",
        ")\n",
        "trainer.train_standard(train_steps)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cbdad3e12a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstep_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m55\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mvideo_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;31m# paste in appropriate path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpretrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'video_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVP-03PSGlaC"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97lWa-3vQW32"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}